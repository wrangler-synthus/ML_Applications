{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T07:05:49.601953Z",
     "start_time": "2019-07-26T07:05:48.756888Z"
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy\n",
    "import scipy.optimize\n",
    "import string\n",
    "from sklearn import linear_model\n",
    "from nltk.stem.porter import PorterStemmer # Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Data Processing\n",
    "\n",
    "###  Read the data and Fill your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset which is used can be found at [amazon-reviews-us-Sports](https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Sports_v1_00.tsv.gz).\n",
    "\n",
    "We can take any other dataset from this official github sit of tensorflow datasets [Similar Datasets](https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/url_checksums/amazon_us_reviews.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T09:10:04.881563Z",
     "start_time": "2019-07-26T09:09:35.266702Z"
    }
   },
   "outputs": [],
   "source": [
    "path = 'data/amazon_reviews_us_Sports_v1_00.tsav.gz'\n",
    "\n",
    "f = gzip.open(path, 'rt', encoding='utf8')\n",
    "\n",
    "header = f.readline()\n",
    "header = header.strip().split('\\t')\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for line in f:\n",
    "    fields = line.strip().split('\\t')\n",
    "    d = dict(zip(header, fields))\n",
    "    d['star_rating'] = int(d['star_rating'])\n",
    "    d['helpful_votes'] = int(d['helpful_votes'])\n",
    "    d['total_votes'] = int(d['total_votes'])\n",
    "    d['verified_purchase'] = d['verified_purchase'] == 'Y'\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Split the data into a Training and Testing set\n",
    "\n",
    "First shuffle your data, then split your data. Have Training be the first 80%, and testing be the remaining 20%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T09:11:06.839339Z",
     "start_time": "2019-07-26T09:11:06.780285Z"
    }
   },
   "outputs": [],
   "source": [
    "N = len(dataset)\n",
    "trainingSet = dataset[:int(N*0.8)]\n",
    "testSet = dataset[int(N*0.8):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now delete your dataset\n",
    "You don't want any of your answers to come from your original dataset any longer, but rather your Training Set, this will help you to not make any mistakes later on, especialy when referencing the checkpoint solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T09:12:42.927675Z",
     "start_time": "2019-07-26T09:12:42.886578Z"
    }
   },
   "outputs": [],
   "source": [
    "del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Extracting Basic Statistics\n",
    "\n",
    "1. How many entries are in your dataset?\n",
    "2. Pick a non-trivial attribute (i.e. verified purchases in example), what percentage of your data has this atttribute?\n",
    "3. Pick another different non-trivial attribute, what percentage of your data share both attributes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T09:25:07.648862Z",
     "start_time": "2019-07-26T09:25:06.496315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of entries in (training) dataset:  3880288\n",
      "Fraction of reviews from verified purchases:  0.9077135511590892\n",
      "Fraction of reviews from verified purchases and have 5-star ratings:  0.5829724494676684\n"
     ]
    }
   ],
   "source": [
    "print('Numer of entries in (training) dataset: ', len(trainingSet))\n",
    "\n",
    "verified_purchases = [d['verified_purchase'] for d in trainingSet]\n",
    "print('Fraction of reviews from verified purchases: ', sum(verified_purchases) / len(verified_purchases))\n",
    "\n",
    "verified_purchases_5_star_ratings = [d for d in trainingSet if d['star_rating'] == 5 and d['verified_purchase']]\n",
    "print('Fraction of reviews from verified purchases and have 5-star ratings: ',\n",
    "      len(verified_purchases_5_star_ratings) / len(trainingSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Classification\n",
    "\n",
    "Next you will use our knowledge of classification to extract features and make predictions based on them. Here you will be using a Logistic Regression Model.\n",
    "\n",
    "### Define the feature function\n",
    "\n",
    "This implementation will be based on any two attributes from your dataset. You will be using these two attributes to predict a third."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T09:26:18.878763Z",
     "start_time": "2019-07-26T09:26:18.876046Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature(d):\n",
    "    feat = [1, d['star_rating'], len(d['review_body'])]\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit your model\n",
    "\n",
    "1. Create your __Feature Vector__ based on your feature function defined above. \n",
    "2. Create your __Label Vector__ based on the \"verified purchase\" column of your training set.\n",
    "3. Define your model as a __Logistic Regression__ model.\n",
    "4. Fit your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T09:27:41.124893Z",
     "start_time": "2019-07-26T09:27:27.335609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector = [feature(d) for d in trainingSet]\n",
    "\n",
    "label_vector = [d['verified_purchase'] for d in trainingSet]\n",
    "\n",
    "model = linear_model.LogisticRegression(solver='lbfgs')\n",
    "\n",
    "model.fit(feature_vector, label_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Accuracy of Your Model\n",
    "\n",
    "1. Make __Predictions__ based on your model.\n",
    "2. Compute the __Accuracy__ of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T09:28:58.670545Z",
     "start_time": "2019-07-26T09:28:50.978811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.907281882169571\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE\n",
    "predictions = model.predict(feature_vector)\n",
    "\n",
    "corrects = predictions == label_vector\n",
    "accuracy = sum(corrects) / len(corrects)\n",
    "print('Accuracy = ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Regression\n",
    "\n",
    "In this section you will start by working though two examples of altering features to further differentiate. Then you will work through how to evaluate a Regularaized model.\n",
    "\n",
    "For this example you will be working with the dataset in the example notebook. This dataset includes reviews that you will be doing a few regression tasks on. The dataset can be found [here.](https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Home_Improvement_v1_00.tsv.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T09:33:11.340377Z",
     "start_time": "2019-07-26T09:32:56.136900Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \"data/amazon_reviews_us_Home_Improvement_v1_00.tsv.gz\"\n",
    "\n",
    "f = gzip.open(path, 'rt', encoding=\"utf8\")\n",
    "header = f.readline()\n",
    "header = header.strip().split('\\t')\n",
    "reg_dataset = []\n",
    "for line in f:\n",
    "    fields = line.strip().split('\\t')\n",
    "    d = dict(zip(header, fields))\n",
    "    d['star_rating'] = int(d['star_rating'])\n",
    "    reg_dataset.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Words in a Sample Set\n",
    "\n",
    "We are going to work with a new dataset here, as such we are going to take a smaller portion of the set and call it a Sample Set. This is because stemming on the normal training set will take a very long time. (Feel free to change sampleSet -> reg_dataset if you would like to see the difference for yourself)\n",
    "\n",
    "1. Count the number of unique words found within the 'review body' portion of the sample set defined below, making sure to __Ignore Punctuation and Capitalization__.\n",
    "2. Count the number of unique words found within the 'review body' portion of the sample set defined below, this time with use of __Stemming,__ __Ignoring Puctuation,__ ___and___ __Capitalization__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T09:34:58.015285Z",
     "start_time": "2019-07-26T09:34:57.935813Z"
    }
   },
   "outputs": [],
   "source": [
    "wordCount = defaultdict(int)\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "wordCountStem = defaultdict(int)\n",
    "stemmer = PorterStemmer() #use stemmer.stem(stuff)\n",
    "\n",
    "#SampleSet and y vector given\n",
    "sampleSet = reg_dataset[:2*len(reg_dataset)//10]\n",
    "y_reg = [d['star_rating'] for d in sampleSet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T09:53:41.310467Z",
     "start_time": "2019-07-26T09:49:36.043182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique words in 'review body' of sampleSet, ignoring punctuation & capitalization:\n",
      " 156174\n",
      "# of unique words in 'review body' of sampleSet, using stemming & ignoring punctuation & capitalization:\n",
      " 131821\n"
     ]
    }
   ],
   "source": [
    "for d in sampleSet:\n",
    "    review = ''.join([x for x in d['review_body'].lower() if not x in punctuation])\n",
    "    for word in review.split():\n",
    "        wordCount[word] += 1\n",
    "        \n",
    "for d in sampleSet:\n",
    "    review = ''.join([x for x in d['review_body'].lower() if not x in punctuation])\n",
    "    for word in review.split():\n",
    "        stemmed_word = stemmer.stem(word)\n",
    "        wordCountStem[stemmed_word] += 1\n",
    "        \n",
    "print(\"# of unique words in 'review body' of sampleSet, ignoring punctuation & capitalization:\\n\",\n",
    "      len(wordCount))\n",
    "print(\"# of unique words in 'review body' of sampleSet, using stemming & ignoring punctuation & capitalization:\\n\",\n",
    "      len(wordCountStem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Classifiers\n",
    "\n",
    "1. Given the feature function and your counts vector, __Define__ your X_reg vector. (This being the X vector, simply labeled for the Regression model)\n",
    "2. __Fit__ your model using a __Ridge Model__ with (alpha = 1.0, fit_intercept = True).\n",
    "3. Using your model, __Make your Predictions__.\n",
    "4. Find the __MSE__ between your predictions and your y_reg vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T09:55:26.276044Z",
     "start_time": "2019-07-26T09:55:26.118760Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_reg(datum):\n",
    "    feat = [0] * len(words)\n",
    "    r = ''.join([c for c in datum['review_body'].lower() if not c in punctuation])\n",
    "    for w in r.split():\n",
    "        if w in wordSet:\n",
    "            feat[wordId[w]] += 1\n",
    "    return feat\n",
    "\n",
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "\n",
    "#Note: increasing the size of the dictionary may require a lot of memory\n",
    "words = [x[1] for x in counts[:100]]\n",
    "\n",
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T10:00:24.417467Z",
     "start_time": "2019-07-26T10:00:10.470762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 1.2681907016075111\n"
     ]
    }
   ],
   "source": [
    "X_reg = [feature_reg(d) for d in sampleSet]\n",
    "\n",
    "model = linear_model.Ridge(alpha=1.0, fit_intercept=True)\n",
    "model.fit(X_reg, y_reg)\n",
    "\n",
    "predictions = model.predict(X_reg)\n",
    "\n",
    "mse = MSE(predictions, y_reg)\n",
    "print('MSE =', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Recommendation Systems\n",
    "\n",
    "You will use your knowledge of simple similarity-based recommender systems to make calculate the most similar items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T10:03:16.491381Z",
     "start_time": "2019-07-26T10:03:16.487182Z"
    }
   },
   "outputs": [],
   "source": [
    "attribute_1 = defaultdict(set)\n",
    "attribute_2 = defaultdict(set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill your Dictionaries\n",
    "\n",
    "1. For each entry in your training set, fill your default dictionaries (defined above). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T10:08:09.456399Z",
     "start_time": "2019-07-26T10:08:08.300786Z"
    }
   },
   "outputs": [],
   "source": [
    "itemNames = {}\n",
    "\n",
    "for d in sampleSet:\n",
    "    user, item = d['customer_id'], d['product_id']\n",
    "    attribute_1[item].add(user)\n",
    "    attribute_2[user].add(item)\n",
    "    itemNames[item] = d['product_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T10:10:19.678606Z",
     "start_time": "2019-07-26T10:10:19.672992Z"
    }
   },
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom\n",
    "\n",
    "def mostSimilar(n, m): #n is the entry index\n",
    "    similarities = []  #m is the number of entries\n",
    "    users = attribute_1[n]\n",
    "    for i2 in attribute_1:\n",
    "        if i2 == n: continue\n",
    "        sim = Jaccard(users, attribute_1[n])\n",
    "        similarities.append((sim,i2))\n",
    "    similarities.sort(reverse=True)\n",
    "    return similarities[:m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Predictions\n",
    "\n",
    "1. Calculate the __10__ most similar entries to the __first__ entry in your dataset, using the functions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T10:14:42.867045Z",
     "start_time": "2019-07-26T10:14:40.541375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for SadoTech Model C Wireless Doorbell Operating at over 500-feet Range with Over 50 Chimes, No Batteries Required for Receiver, (Various Colors):\n",
      "\n",
      "1 :  Fibaro Z-Wave Motion Sensor - FGMS-001\n",
      "\n",
      "2 :  PowerHalo Sliding Gate Opener Sliding Gate Opener Kit Sliding Gate Opener Remote Auto Close Particularly Simple Installation with Comprehensive Interface\n",
      "\n",
      "3 :  Newsee Decals Dream Until Your Dreams Come True Wall Famous PVC Wall Sticker Decal Quote Art Vinyl Black\n",
      "\n",
      "4 :  Antique Gold Swing Arm Floor Lamp 58\"\n",
      "\n",
      "5 :  REEGE Premium Multifunction Toilet Handheld Bidet Shattaf Cloth Diaper Sprayer Shower with Brass Material\n",
      "\n",
      "6 :  Double Cylinder Satin Nickel Finish Deadbolt Lock w/ Keys - Fits All Doors\n",
      "\n",
      "7 :  Alarm Detects One Drop of Water! Leak Detector for your basement. The only water sensor equipment on the market that detects a single drop of water and small amounts of moisture.\n",
      "\n",
      "8 :  Classic with Nylon FBA(Ready to Ships)\n",
      "\n",
      "9 :  Sentrel SSK60367831GB Royale Tub/Shower Surround Bundle, 60\" x 36\" x 78\", Golden Beaches\n",
      "\n",
      "10 :  Everbilt Flush Valve Shank Washer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = sampleSet[0]['product_id']\n",
    "print('Recommendations for ' + itemNames[query] + ':\\n')\n",
    "recommendations = [itemNames[x[1]] for x in mostSimilar(query, 10)]\n",
    "for i, recommendation in enumerate(recommendations):\n",
    "    print(i + 1, ': ', recommendation + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
